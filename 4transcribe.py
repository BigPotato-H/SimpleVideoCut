# scripts/transcribe.py
import json
from pathlib import Path
from faster_whisper import WhisperModel
from config import CUT_AUDIO, SUBTITLE_JSON



def run(
    audio_path: Path = CUT_AUDIO,
    output_path: Path = SUBTITLE_JSON,
    model_size="medium",  # ä¸­æ–‡å£æ’­æ¨è medium
    device="cpu",         # æœ‰ GPU å¯æ”¹æˆ "cuda"
    compute_type="int8"   # cpu å‹å¥½
):
    print("ğŸ”Š åŠ è½½ Whisper æ¨¡å‹...")
    model = WhisperModel(model_size, 
                         device=device, 
                         compute_type=compute_type)
                        #  cache_dir=Path("D:/0hn/py-code/SimpleVideoCut/whisper_cache"))

    print("ğŸ“ è¯†åˆ«ä¸­...")
    segments, info = model.transcribe(
        str(audio_path),
        language="zh",
        beam_size=5,
        vad_filter=True,  # å»æ‰é™éŸ³
        vad_parameters=dict(min_silence_duration_ms=300)
    )

    subtitles = []
    for seg in segments:
        subtitles.append({
            "start": round(seg.start, 3),
            "end": round(seg.end, 3),
            "text": seg.text.strip()
        })

    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(subtitles, f, ensure_ascii=False, indent=2)

    print(f"âœ… å­—å¹•ç”Ÿæˆå®Œæˆ: {output_path}")
    print(f"ğŸ“„ æ®µè½æ•°: {len(subtitles)}")

if __name__ == "__main__":
    run()
